{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#packages needed\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import scrapy \n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "#matplot.lib packages are updating a function that Networkx are using - this gives an error message. This line ignore that error message.     \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "#This imports the .csv file from Anders G google drive account. Could not make it work to import the file directly from the sheet\n",
    "orig_url='https://drive.google.com/file/d/1LbA7E94eJxVUv4lq8lVBM9q1ewWc_6iV/view?usp=sharing'\n",
    "\n",
    "file_id = orig_url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
    "url = requests.get(dwn_url).text\n",
    "csv_raw = StringIO(url)\n",
    "df = pd.read_csv(csv_raw)\n",
    "\n",
    "def df_graph_explore(search, numberTags = 45, gexfFile_full = False, gexfFile_top = False, csvFile_top = False, csvFile_full = False, printGraph = True, figureSize = [20, 10], printtop5 = True): \n",
    "    '''\n",
    "    Takes a pandas dataframe and explores it.\n",
    "    \n",
    "    search,               #This is the search term. use the \"|\" operator to include more search terms, eg. search = \"google|twitter\". The search is case insensitive \n",
    "    numberTags=45,        #This is the number of tags with the highest degree scorer to include in the network graph  \n",
    "    gexfFile_full=False,  #If True - This writes a .gexf file with all the nodes \n",
    "    gexfFile_top=False,   #If True - This writes a .gexf file with the highest degree scorer according to the \"numberTags\" \n",
    "    csvFile_top=False,    #If True - This writes a .csv file with the 5 most cited articles\n",
    "    csvFile_full=False,   #If True - This writes a .csv file with all the articles \n",
    "    printGraph = True     #If True - This prints out a network graph with the number of tags according to \"numberTags\"\n",
    "    figureSize = [20, 10] #This changes the size of the printed figure.\n",
    "    printtop5 = True      #If True - This prints out the titles of the top 5 most cited articles \n",
    "    \n",
    "    The Dataframe must be called \"df\" and must include the collumns: \"Keywords Author+Index\", \"Title\", \"Year\", \"Cited by\" \n",
    "    '''\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "#merge collumns in to a new colms called \"text\", this new colmn can afterwards been searched though for interesting words\n",
    "    #df['allKeywords'] = df['Author Keywords'] + \":\" + df['Index Keywords'] #There is a problem with this line. I need to merge them better than just merge, have to deal with missing val\n",
    "    df['text'] = df['Abstract'] + \":\" + df['Title'] + \":\" + df['Keywords Author+Index'] #the merging\n",
    "#df.loc[0, 'text'] #uncomment to look at the result for the first row \n",
    "\n",
    "#Make the text in \"text\" lowercase so it is easier to search. \n",
    "    df['text'] = df['text'].str.lower() \n",
    "\n",
    "#the search for the desired word. \n",
    "    search1 = search.lower() #make sure the search are lower case\n",
    "    df1 = df[df['text'].str.contains(search1)]\n",
    "\n",
    "#cleaning up the result a bit. eg. in order to avoid the comma \",\" to be a node in the network graph later on. (maybe more cleaning is nessasary) \n",
    "    df7 = df1[\"Keywords Author+Index\"].str.replace(\"^;\", \"\").str.replace(\",\",\"\").str.lower()\n",
    "\n",
    "#here we are splitting the tags from one list into one tag pr. list. \n",
    "    df2 = df7.str.split(\";\")\n",
    "\n",
    "#here we are making the edgelist, we are relating each tags with the other tags from the same observation\n",
    "    edge = [[i[0],j] for i in df2 for j in i[1:]] #I am not completely sure how this works. But it does.. \n",
    "\n",
    "#This makes a new dataframe with the colmns \"from\" and \"to\" (it does not matter what is \"from\" and what is \"to\" since it is a undirected graph)\n",
    "    edgeList=pd.DataFrame(edge, columns=[\"from\", \"to\"])\n",
    "\n",
    "#Loading edelist (directly as a list) into the networkx package. Now we have a network structure and are not working with a dataframe any more\n",
    "    tags = nx.from_edgelist(edge)\n",
    "    tags_big = nx.from_edgelist(edge)\n",
    "\n",
    "#this prints out the informations about the network. This is the BIG holistic network - before we are filtering it down. \n",
    "#print(nx.info(tags))\n",
    "\n",
    "####This sorts the nodes according to degree.  \n",
    "#sorted(tags.degree, key=lambda x: x[1], reverse=True) #delete this one i think..  \n",
    "    sortedTags = sorted(tags.degree, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#remove tags according to \"numberTags\" eg. numberTags = 50\n",
    "    topTags = sortedTags[numberTags:] #here we are taking all the tags that are not(!) the biggest degree \"numberTags\" \n",
    "    a=[] #this makes an empty list that we are using in the for loop\n",
    "    for t in topTags: \n",
    "        b=t[0] #this takes the first (desired) element from each list\n",
    "        a.append(b) #this puts that element into the newly made list - now we have a list with all the nodes that are NOT the x biggest node degree\n",
    "\n",
    "    tags.remove_nodes_from(a) #this removes the small nodes from the graph. \n",
    "    sorted(tags.degree, key=lambda x: x[1], reverse=True) #here we are soring the nodes inorder to see what are included\n",
    "                             #Remenber that the new degree score are in relation to the new graph, not the original graph  \n",
    "    \n",
    "\n",
    "#find the biggest degree score to size nodes according to degree scorer that we are gonna use later.  \n",
    "    biggest = sorted(tags.degree, key=lambda x: x[1], reverse=True)#again we are sorting the nodes - here to find the biggest degree score.   \n",
    "    biggest1 = biggest[0][1]# here we are finding the biggest node degree score. And puts it in the variable \"biggest1\"\n",
    "\n",
    "### This is to Remove isolated nodes. It could make most sence to include them. But is messes with the visualizations. But they should be included since they are among the biggest nodes \n",
    "#list(nx.isolates(tags)) # this does not work\n",
    "    tags.remove_nodes_from(list((nx.isolates(tags)))) #this works\n",
    "\n",
    "#math stuff to make the node sizes:\n",
    "    nodeSizeHigh = 3000 #this makes the biggest node_size() to the nx.draw() function\n",
    "    nodeSizeLow = 50 #this is the smalles\n",
    "    nodeSizeMath = nodeSizeHigh-nodeSizeLow\n",
    "    multiply = nodeSizeMath/biggest1\n",
    "\n",
    "#Here we are drawing the graph! WUHU!      #more stuff could be done. It could be cool to make a \"no overlap\" function. I cant find any to networkX package, but it must exist.\n",
    "    if printGraph == True:\n",
    "        d = dict(tags.degree)\n",
    "        plt.rcParams['figure.figsize'] = figureSize #this scales how big the printing of the graph should be. \n",
    "        nx.draw(tags, \n",
    "                with_labels=True,     #includes labels to the graph\n",
    "                font_size = 15,       #label font size\n",
    "                node_color=\"skyblue\", #color of the nodes\n",
    "                edge_color=\"skyblue\", #edge color\n",
    "                alpha = 0.7,          #edge transparency\n",
    "                pos=nx.fruchterman_reingold_layout(tags),   #the graph layout (spatialization) here: \"fruchterman_reingold\" layout\n",
    "        #pos=nx.spring_layout(tags, scale=2),       #alternative graph layout (spatialization)\n",
    "                node_size=[v*multiply+nodeSizeLow for v in d.values()]) #this makes the nodes different sizes accoring to their degree score\n",
    "\n",
    "#this gives information about the graph \n",
    "#print(nx.info(tags))\n",
    "\n",
    "#makes a data.frame with the included articles. Sorted by \"cited by\"\n",
    "    dataframe = df1.loc[:,[\"Title\", \"Year\", \"Cited by\", \"Keywords Author+Index\", \"Abstract\"]].sort_values(by=['Cited by', \"Year\"], ascending=False).reset_index(drop=True) #here we have to reset the index in order to .loc the top 5 articles in the next line \n",
    "\n",
    "#get top 5 cited articles\n",
    "    dataframe_top5 = dataframe.loc[0:6, \"Title\"]\n",
    "    dftop5= (list(dataframe_top5))\n",
    "    if printtop5 == True: \n",
    "        print(\"          The 5 most cited articles are:\")\n",
    "        print(\"\")\n",
    "        print(dftop5)\n",
    "\n",
    "    dfLen = len(df.index)\n",
    "    df1Len = len(df1.index)\n",
    "    procent = df1Len/dfLen*100\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"          \", df1Len, \" articles out of \", dfLen, \" contains the word: \", \"'\", search ,\"'\", sep='')\n",
    "    print(\"          That is: \", round(procent,2), \" procent of the total number of articles\", sep='')\n",
    "    print(\"\")\n",
    "    \n",
    "#making the name to the .gexf file\n",
    "    gexf = \".gexf\"\n",
    "    scopusGrapher = \"dfGraphExplore_\"\n",
    "\n",
    "    top=\"_top\"\n",
    "    nr = str(numberTags)\n",
    "    gexfName_top = scopusGrapher+search+top+nr+gexf\n",
    "\n",
    "    full=\"_all\"\n",
    "    nr1 =str(dfLen)\n",
    "    gexfName_full = scopusGrapher+search+full+nr1+gexf\n",
    "\n",
    "    csv = \".csv\"\n",
    "    csvName_full = scopusGrapher+search+full+nr1+csv\n",
    "\n",
    "    nr3 = \"5\"\n",
    "    csvName_top = scopusGrapher+search+top+nr3+csv\n",
    "\n",
    "    df1['indexNr'] = df1.index+1\n",
    "    dataframe_1 = df1.loc[:,[\"indexNr\", \"Title\", \"Year\", \"Cited by\", \"Keywords Author+Index\", \"Abstract\"]].sort_values(by=['Cited by', \"Year\"], ascending=False).reset_index(drop=True) #here we have to reset the index in order to .loc the top 5 articles in the next line\n",
    "    dataframe_top5_1 = dataframe_1.loc[0:4, :]\n",
    "\n",
    "# makes gexf files if statement is true     \n",
    "    if gexfFile_full == True:\n",
    "        nx.write_gexf(tags_big, gexfName_full)\n",
    "        print(\"The file: '\", gexfName_full, \"' have been saved to your computer\", sep='')\n",
    "\n",
    "    if gexfFile_top == True:\n",
    "        nx.write_gexf(tags, gexfName_top)\n",
    "        print(\"The file: '\", gexfName_top, \"' have been saved to your computer\", sep='')\n",
    "# makes gcsv files if statement is true\n",
    "    if csvFile_full == True:\n",
    "        dataframe_1.to_csv(csvName_full, encoding='utf-8')\n",
    "        print(\"The file: '\", csvName_full, \"' have been saved to your computer\", sep='')\n",
    "\n",
    "    if csvFile_top == True:\n",
    "        dataframe_top5_1.to_csv(csvName_top, encoding='utf-8')\n",
    "        print(\"The file: '\", csvName_top, \"' have been saved to your computer\", sep='') \n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"          Here is the network graph showing the \", numberTags, \" most used tags related to \", \"'\", search, \"'\", sep='')    \n",
    "    \n",
    "    #this removes a warning that I am quite sure are not a problem:\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    \n",
    "#The Function\n",
    "#df_graph_explore(search, numberTags = 45, gexfFile_full = False, gexfFile_top = False, csvFile_top = False, csvFile_full = False, printGraph = True, figureSize = [20, 10], printtop5 = True) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
